<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>PCD 2018 - L17</title>

		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/white.css">

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>
	</head>
	<body>
		<div class="reveal">
			<div class="slides">
			  <section data-markdown data-separator="^\r?\n---\r?\n$" data-separator-vertical="^\n\n">
	        <textarea data-template>

# PCD2018 - 17

---

# Parallel Streams

---

# Opportunità


Lo Stream è una diversa rappresentazione dell'iterazione su di un insieme di oggetti.

In particolare, rappresenta l'iterazione su di un insieme di cardinalità non nota, potenzialmente infinita.


In cambio di alcune restrizioni sulle operazioni possibili e della cessione del controllo sull'ordine di iterazione otteniamo:


* una API per comporre passi di elaborazione riusabili su di una successione di oggetti


* una reificazione della trasformazione, che ne permette il riuso su sorgenti diverse ed il test in isolamento


* la promozione di un approccio funzionale al trattamento iterativo dei dati


* la disponibilità di uno stile espressivo e dichiarativo per descrivere una ampia classe di elaborazioni


![Devoxx](imgs/l5/devoxx.jpg) <!-- .element: style="width: 80%" -->

Note: https://twitter.com/mariofusco/status/927819214920081409 (Devoxx 2017)


* un modello di esecuzione in cui esecuzione sequenziale e parallela non richiedono modifiche al codice


In cosa sono differenti gli Stream dalle Collezioni?

Note: nell'enfasi che danno alla conservazione dei dati rispetto alla loro manipolazione.


La caratteristica principale di una Collezione è la performance dell'accesso ai contenuti.

L'algoritmo che usa quei contenuti è completamente estraneo a queste considerazioni.


Uno Stream richiede la definizione dell'algoritmo di calcolo che avverrà sopra i suoi elementi.

Questi ultimi non possono essere acceduti direttamente, e l'algoritmo non ha nessun controllo sul loro recupero.


Lo Stream perciò ha un certo il controllo sull'algoritmo, e può usare questo controllo per prendere decisioni su come eseguirlo.

---

# Stream Flags


La sorgente di uno Stream può dichiarare alcune *caratteristiche* che gli operatori intermedi possono verificare e che l'operazione terminale usa per prendere decisioni sulla esecuzione.

Note: che non avviene mai prima dell'attivazione dell'operazione terminale.


|Flag|Caratteristica|
|-|-|
|CONCURRENT|Parallelizzabile|
|DISTINCT|Elementi distinti|
|IMMUTABLE|Immutabile durante il consumo|


|Flag|Caratteristica|
|-|-|
|NONNULL|Elementi non nulli|
|ORDERED|Elementi ordinati|
|SIZED|Dimensione nota|


|Flag|Caratteristica|
|-|-|
|SORTED|Ordinamento definito|
|SUBSIZED|Suddivisioni di dimensione nota|


L'operazione terminale ha piena visibilità, prima di cominciare a lavorare, di quali sono le caratteristiche della pipeline di esecuzione, e può quindi prendere decisioni in merito.


`pcd2018.streams.CountStream`
```
long cnt = IntStream.range(1, 20)
  // .parallel()
  .map((i) -> {
  System.out.println(i);
  return i * 2;
}).limit(5).count();
System.out.println(">" + cnt);
```

Note: Notate come, se l'esecuzione è seriale o parallela, il risultato è differente: l'operazione terminale `count()` decide che non ha bisogno di eseguire le operazioni `map` e ricava direttamente il conteggio.
Ovviamente, l'effetto collaterale della stampa dell'indice corrente è illegale, quindi non abbiamo nessuna garanzia sulla sua esecuzione.


Una pipeline può essere eseguita in modo sequenziale o parallelo semplicemente configurandola come tale.


```java
/**
 * Base interface for streams, which are sequences
 * of elements supporting sequential and parallel
 * aggregate operations.
 */
interface BaseStream<T,S extends BaseStream<T,S>>
```


```java
/**
 * Returns an equivalent stream that is parallel.
 * May return itself, either because the stream
 * was already parallel, or because the underlying
 * stream state was modified to be parallel.
 */
S parallel()
```


```java
/**
 * Returns an equivalent stream that is sequential.
 * May return itself, either because the stream
 * was already sequential, or because the underlying
 * stream state was modified to be sequential.
 */
S sequential()
```

Note: Attenzione: l'ultimo elemento lungo la catena vince: non si possono costruire pipeline di concorrenza mista.
O meglio, è così attualmente. Un aggiornamento della libreria potrebbe cambiare le cose.


Una pipeline **ORDERED** garantisce di ritornare gli elementi nell'ordine in cui sono stati emessi.

I passi intermedi che mantengono questa caratteristica non modificano l'ordine.

Note: Attenzione SORTED è un'altra cosa


L'ordinamento è conservato, se possibile, anche dopo una esecuzione parallela


`pcd2018.streams.OrderedStream`
```java
IntStream.range(1, 20).parallel().map((i) -> {
  System.out.println(i + " " +
    Thread.currentThread().getName());
  return i * 2;
}).forEachOrdered((i) -> {
  System.out.println(">>> " + i);
});
```

Note: si può notare come il lavoro viene distribuito a più thread, ma il risultato finale sia comunque ordinato


Una pipeline **SORTED** mantiene gli elementi ordinati secondo il loro ordinamento naturale o dato da un `Comparator`.


La caratteristica **DISTINCT** garantisce che non ci siano due elementi uguali secondo `equals()`.


Una pipeline **SIZED** garantisce una dimensione nota. Se inoltre è **SUBSIZED** vuol dire che può fornire efficientemente dei sottoinsiemi dimensionati per l'esecuzione parallela.


Le operazioni che passiamo ai passi intermedi devono essere:

* non invasive: non devono modificare od interferire con gli elementi dello stream
* (nella maggior parte dei casi) prive di stato interno: devono essere cioè _funzioni pure_


Alcune operazioni sono identificate come <br/>*short-circuiting*: significa che possono interrompere l'esecuzione della pipeline prima dell'esame di tutti gli elementi.


```java
/**
 * Returns whether any elements of this stream match
 * the provided predicate. May not evaluate the
 * predicate on all elements if not necessary for
 * determining the result.
 */
boolean anyMatch(Predicate<? super T> predicate)
```


```java
/**
 * Returns an Optional describing some element of the
 * stream, or an empty Optional if the stream is empty.
 * The behavior of this operation is explicitly
 * nondeterministic; it is free to select any element
 * in the stream.
 */
Optional<T> findAny()
```

Note: il comportamento di `findAny()` è pensato per la massima performance negli stream paralleli.


`pcd2018.streams.CandidateNumber`
```java
public class CandidateNumber {
  public final int n;
  public final List<Integer> divisors;

  CandidateNumber(int n, List<Integer> divisors) {
    this.n = n;
    this.divisors = divisors;
  }
}
```

Note: una struttura dati per verificare se un numero può essere candidato ad essere primo.


`pcd2018.streams.Divisors`
```java
public class Divisors implements
  Function<Integer, CandidateNumber> {

  @Override
  public CandidateNumber apply(Integer n) {

    ...

    return new CandidateNumber(n, divs);
  }
}
```

Note: questa funzione produce, da un intero, un `CandidateNumber` con tutti i suoi divisori che può così essere controllato.


`pcd2018.streams.Perfect`
```java
public class Perfect implements Predicate<CandidateNumber> {

  @Override
  public boolean test(CandidateNumber c) {
    Integer sum = c.divisors.stream()
        .collect(Collectors.summingInt((Integer n) -> n));
    return (sum + 1) == c.n;
  }

}
```

Note: questa classe è un predicato, cioè una funzione booleana su di un oggetto. Ci dice quando un `CandidateNumber` è un numero perfetto.


`pcd2018.streams.PerfectStream`
```java
List<CandidateNumber> match = IntStream.range(30, 100000)
  .boxed().parallel().map(new Divisors())
  .filter(new Perfect()).findAny().stream()
  .collect(Collectors.toList());

match.forEach(x -> { System.out.println(x); });
```

Note: otteniamo così una ricerca, parallela, che si ferma al primo risultato trovato.


Altre operazioni sono dette _stateful_: può necessitare di consumare tutto o gran parte dell'input per poter emettere l'output mantenendo le caratteristiche desiderate (per es. ordinamento).

Note: questo può rendere alcune operazioni apparentemente semplici in realtà molto costose.


```java
/**
 * Returns a stream consisting of the elements of this
 * stream, truncated to be no longer than maxSize in
 * length.
 */
Stream<T> limit(long maxSize)
```

Note: attenzione che limit è _stateful_ perché deve ritornare i **primi** elementi.


`pcd2018.streams.AllPerfectStream`
```java
IntStream.range(10, 10000).boxed().parallel()
  .map(new Divisors()).filter(new Perfect()).limit(2)
  .forEach((CandidateNumber c) -> {
    System.out.println(">>> " + c.toString());
  });
```

Note: vengono ritornati i primi due elementi, in ordine. E non viene ritornato 8128.

---

# SplitIterator


Per esprimere una sorgente in grado di essere parallelizzabile non è sufficiente l'API esposta da `Supplier` o `Iterator`.


Servono infatti dei metodi che consentano alla sorgente di esplicitare le opportunità di suddivisione dello stream in rami di esecuzione indipendenti.


```java
/**
 * An object for traversing and partitioning elements
 * of a source.
 *
 */
public interface Spliterator<T>
```


Il metodo di avanzamento diventa `tryAdvance()`, che ribalta il funzionamento dell'iterator: <br/> non è l'utilizzatore che ottiene il nuovo elemento, ma è lo stream che fornisce l'elemento al codice che deve operarci sopra.


```java
/**
 * If a remaining element exists, performs the given
 * action on it, returning true; else returns false.
 *
 */
boolean tryAdvance(Consumer<? super T> action)
```


`Splititerator` aumenta l'espressività di `Iterator` aggiungendo metodi per:
* stimare gli elementi rimanenti
* esplicitare le caratteristiche della sorgente
* attraversare in massa gli elementi rimanenti
* suddividere l'iterazione in più rami

Note: manca invece (coerentemente con la definizione di Stream) l'operazione di rimozione di un elemento


```java
/**
 * Returns an estimate of the number of elements that
 * would be encountered by a forEachRemaining()
 * traversal, or returns Long.MAX_VALUE if infinite,
 * unknown, or too expensive to compute.
 *
 * @return the estimated size
 */
long estimateSize()
```


```java
/**
 * Returns a set of characteristics of this
 * Spliterator and its elements.
 *
 * @return a representation of characteristics
 */
int characteristics()
```

Note: notare il tipo di ritorno. Ci si attende che ogni chiamata a questo metodo dia lo stesso risultato; eventualmente, il risultato può cambiare dopo la separazione.


```java
/**
 * Performs the given action for each remaining element,
 * sequentially in the current thread, until all elements
 * have been processed or the action throws an exception.
 *
 */
default void forEachRemaining(Consumer<? super T> action)
```

Note: l'implementazione di default chiama tryAdvance per ogni elemento


```java
/**
 * If this spliterator can be partitioned, returns a
 * Spliterator covering elements, that will, upon return
 * from this method, not be covered by this Spliterator.
 *
 * @return a Spliterator covering some portion of the
 *           elements, or null if this spliterator cannot
 *           be split
 *
 */
Spliterator<T> trySplit()
```

Note: le condizioni che questa chiamata deve rispettare sono molto complesse.


Con il supporto di queste funzioni, lo stream può pianificare efficientemente l'esecuzione delle operazioni terminali.



```java
/**
 * Performs a reduction on the elements of this stream,
 * using the provided identity value and an associative
 * accumulation function, and returns the reduced value.
 *
 * @param identity the identity value for the accumulating
 *                   function
 * @param accumulator an associative, non-interfering,
 *                      stateless function for combining
 *                      two values
 * @result the result of the reduction
 *
 */
T reduce(T identity, BinaryOperator<T> accumulator)
```


`pcd2018.streams.StreamReduce`
```
int res = IntStream.range(1, 1001).parallel().
  reduce(0, (a, b) -> {
    System.out.println(a + "+" + b + "=" + (a + b)
      + " " + Thread.currentThread().getName());
    return a + b;
  });
System.out.println(">>>> " + res);
```


```java
/**
 * Performs a mutable reduction operation on the elements
 * of this stream using a Collector.
 *
 * @R the type of the result
 * @A the intermediate accumulation type of the Collector
 * @param the Collector describing the reduction
 * @result the result of the reduction
 */
<R,A> R collect(Collector<? super T,A,R> collector)
```


`pcd2018.streams.StreamCollector`
```java
int res = IntStream.range(1, 1001).boxed().parallel()
  .collect(Collectors.summingInt((i) -> i));
System.out.println(">>>> " + res);
```

---

# Collector


Nell'operazione di riduzione gestita da `reduce` l'accumulazione del risultato avviene creando nuovi valori. Questo però in certi casi non è efficiente.


`pcd2018.streams.StringReduce`
```java
String res = IntStream.range(1, 1001).boxed()
  .map((i) -> i.toString())
  .parallel().reduce("", String::concat);
System.out.println(">>>> " + res);
```

Note: ogni passo di riduzione produce una nuova stringa, sempre più grande, creando una forte pressione per il Garbage Collector.


L'interfaccia `Collector` permette di gestire una riduzione dove l'accumulatore è un oggetto mutabile per ragioni di efficienza.


```java
/**
 * A mutable reduction operation that accumulates input
 * elements into a mutable result container.
 *
 * @T the type of input elements to the reduction
 *      operation
 * @A the mutable accumulation type of the
 *      reduction operation
 * @R the result type of the reduction operation
 */
interface Collector<T,A,R>
```


La classe `Collectors` permette di produrre dei `Collector` a partire dagli elementi di base:

* un `Supplier<A>` del contenitore di risultato
* un `BiConsumer<A,T>` che accumula un elemento nel contenitore


* un `BinaryOperator<A>` che combina due contenitori parziali
* un `Function<A,R>` che dal contenitore ottiene il risultato finale


Combinando questi elementi lo `Stream` ha tutte le parti della strategia per applicare l'algoritmo, e ha le caratteristiche della sorgente per calcolare come organizzare l'esecuzione.


`pcd2018.streams.StringCollector`
```java
String res = IntStream.range(1, 1001).boxed()
  .map((i) -> i.toString()).parallel().collect(
    // supplier
    () -> new StringBuffer(),
    // accumulator
    (acc, el) -> acc.append(el),
    // combiner
    (resA, resB) -> resA.append(resB))
  .toString();
System.out.println(">>>> " + res);
```

Note: applicazione classica del pattern Template Method

---

# Parallel Streams


Gli Stream sono quindi un'ottima astrazione per modellare in modo semplice algoritmi su collezioni di elementi.

Il nostro codice può essere eseguito in parallelo con un semplice cambio di configurazione.


Lo Stream tuttavia di default decide autonomamente quanto parallelismo usare, attraverso il `ForkJoinPool`.

Quanto parallelismo possiamo richiedere?

Note: ForkJoinPool di standard usa #core-1 threads.


**Blocking factor**: <br/>Intensità del calcolo di un algoritmo

Un algoritmo con `BF=0` <br/>occupa costantemente la CPU.

Un algoritmo con `BF=1` <br/>è costantemente in attesa di I/O.


```
              #of cores
#threads <= -------------
                1-BF
```


Se il nostro algoritmo effettua molta I/O può essere utile modificare l'impostazione standard del `ForkJoinPool` per aumentare il numero di thread disponibili.


Dr. Venkat Subramaniam: The Power and Perils of Parallel Streams

https://www.youtube.com/watch?v=0-f-1Cx0HaU

Note: il video è la registrazione di un meetup del (Virtual Java User Group)[https://virtualjug.com/]


Allo stesso tempo l'uso dello Stream come modello di calcolo può grandemente semplificare l'aspetto e quindi la leggibilità e la manutenibilità del nostro codice:


```java
public static double compute1(int n, int k) {
  int index = n;
  int count = 0;
  double result = 0;

  while(count < k) {
    if(isPrime(index)) {
      result += Math.sqrt(index);
      count++;
    }
    index++;
  }
  return result;
}
```


```java
public static double compute2(int n, int k) {
  return Stream.iterate(n, e -> e + 1)
               .filter(Sample::isPrime)
               .limit(k)
               .mapToDouble(Math::sqrt)
               .sum();
}
```

Note: http://blog.agiledeveloper.com/2016/06/infinite-streams-may-remove-accidental_29.html

---

# Approfondimenti


Parallel and Asynchronous Programming with Streams and CompletableFuture by Venkat Subramaniam (Devoxx 2017)

https://www.youtube.com/watch?v=IwJ-SCfXoAU

</textarea>
</section>
        </section>
			</div>
		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.js"></script>

		<script>
			// More info about config & dependencies:
			// - https://github.com/hakimel/reveal.js#configuration
			// - https://github.com/hakimel/reveal.js#dependencies
			Reveal.initialize({
			  slideNumber: 'c/t',
				dependencies: [
					{ src: 'plugin/markdown/marked.js' },
					{ src: 'plugin/markdown/markdown.js' },
					{ src: 'plugin/notes/notes.js', async: true },
					{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } }
				]
			});
		</script>
	</body>
</html>
